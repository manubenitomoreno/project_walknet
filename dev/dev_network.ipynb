{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cadastral data mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first step is reading relevant data to be processed. We store all .CAT files in the same directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos el Notebook de Utils\n",
    "#We read the Utils Notebook\n",
    "%run Utils.ipynb\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\manub\\\\DATA\\\\00-EXTERNO\\\\MANU\\\\CARPIO\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_file = path+\"28_900_U_2021-01-22.CAT\"\n",
    "parcels_file = path+\"28_900_UH_2021-01-23_SHF\\\\PARCELA\\\\PARCELA.SHP\"\n",
    "#access_file = path+\"MADRID\\\\28_900_UA_2020-07-31_SHF\\\\ELEMTEX\\\\ELEMTEXII.SHP\"\n",
    "#network_file = path + \"MADRID\\\\RT_MADRID_INTEREST.shp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work on cadastral .cat\n",
    "It is a structured text file which description can be obtained [here](http://www.catastro.minhap.es/documentos/formatos_intercambio/catastro_fin_cat_2006.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo CAT C:\\Users\\manub\\DATA\\00-EXTERNO\\MANU\\CARPIO\\28_900_U_2021-01-22.CAT: Registro 11\n",
      "Hecho\n",
      "Leyendo CAT C:\\Users\\manub\\DATA\\00-EXTERNO\\MANU\\CARPIO\\28_900_U_2021-01-22.CAT: Registro 13\n",
      "Hecho\n",
      "Leyendo CAT C:\\Users\\manub\\DATA\\00-EXTERNO\\MANU\\CARPIO\\28_900_U_2021-01-22.CAT: Registro 14\n",
      "Hecho\n",
      "Leyendo CAT C:\\Users\\manub\\DATA\\00-EXTERNO\\MANU\\CARPIO\\28_900_U_2021-01-22.CAT: Registro 15\n",
      "Hecho\n"
     ]
    }
   ],
   "source": [
    "df11 = prepare_df(leecat11(cat_file))\n",
    "df13 = prepare_df(leecat13(cat_file))\n",
    "df14 = prepare_df(leecat14(cat_file))\n",
    "df15 = prepare_df(leecat15(cat_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconocido municipio: MADRID\n"
     ]
    }
   ],
   "source": [
    "cityname = df11['NOMMUN'].iloc[0]\n",
    "print(\"Reconocido municipio: \"+cityname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df11[['PCAT','CODPROV','CODINE','NOMPROV','NOMMUN','PCODVIA','PTIPVIA','PNOMVIA','PPNP','PPLE','SUPP','SUPCT','SUPCSR','SUPCBR','SUPCUB','COORX','COORY','DEN_BICE']]\n",
    "df13 = df13[['PCAT','COD_UC','ANOCONS','ANOEXAC']]\n",
    "df14 = df14[['PCAT','NCBI_PC','COD_UC','CDD','TIPREF','ANOREF','ANOEFE','SUPT_CAT']]\n",
    "#Drop common spaces\n",
    "df14 = df14.loc[df14['NCBI_PC'] != \"\"]\n",
    "df15 = df15[['PCAT','NCBI_PC','CODVIA','TIPVIA','NOMVIA','PNP','PLE','NOBI','ANOANT','CDD_BI','SUPCON']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge all four register tables\n",
    "df = merge_and_drop(df15,df14,'right',['PCAT','NCBI_PC'])\n",
    "df = merge_and_drop(df13,df,'right',['PCAT','COD_UC'])\n",
    "df = merge_and_drop(df11,df,'right',['PCAT'])\n",
    "df['PPNP'] = df['PPNP'].fillna(0).astype('int64').astype('str').str.replace(\"0\", \"\")\n",
    "df['PNP'] = df['PNP'].fillna(0).astype('int64').astype('str').str.replace(\"0\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122484"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.PCAT.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bi = df.drop_duplicates(subset = ['PCAT','NCBI_PC'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = pd.pivot_table(df_bi, values='SUPCON', index=['PCAT'],columns=['CDD_BI'], aggfunc=np.sum).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.pivot_table(df_bi, values='SUPCON', index=['PCAT'],columns=['CDD_BI'], aggfunc=lambda x: len(x.unique())).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums.rename(columns = {c:\"S\"+c for c in sums.columns},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.rename(columns = {c:\"N\"+c for c in counts.columns},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels = gpd.read_file(parcels_file)\n",
    "parcels = parcels.dissolve(by = 'REFCAT')\n",
    "parcels = parcels.loc[~parcels['geometry'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels_loaded = pd.merge(parcels,counts,left_index=True,right_index=True,how='left')\n",
    "parcels_loaded = pd.merge(parcels,sums,left_index=True,right_index=True,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [c for c in parcels_loaded.columns if len(c)==2]:\n",
    "    parcels_loaded[p].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159141"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parcels_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels_loaded.to_file(path+cityname+\"_loaded.shp\",driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Land Use Reference points ready\n",
    "Basically, I use cadastral addresses points described [here](http://www.catastro.minhap.es/ayuda/manual_descriptivo_shapefile.pdf), assign the nearest parcel id to each one,and then try to match them to my cadastral records. This point is the closest I can get to the actual entrance of each land use activity, I call it ***'refpoint'***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = gpd.read_file(access_file)\n",
    "#addresses = addresses.loc[addresses['INTEREST']==1]\n",
    "addresses = addresses.loc[~addresses['geometry'].isna()]\n",
    "parcels = gpd.read_file(parcels_file)\n",
    "#parcels = parcels.loc[parcels['INTEREST']==1]\n",
    "parcels = parcels.loc[~parcels['geometry'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the address points\n",
    "addresses = addresses.loc[addresses['TTGGSS'] == '189401']\n",
    "addresses['geometry'] = addresses['geometry'].centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize =(10,10))\n",
    "ax.set_facecolor('black')\n",
    "parcels.plot(ax=ax)\n",
    "addresses.plot(ax=ax,\n",
    "                    color='lightgray',\n",
    "                    markersize = 2)\n",
    "plt.grid(True,color='w', linestyle='-', linewidth=0.3)\n",
    "plt.show();\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Utils.ipynb\n",
    "\n",
    "#Find Nearest Parcels\n",
    "addresses = find_nearest(addresses,parcels,'REFCAT')[['ROTULO','REFCAT','geometry']]\n",
    "display(addresses.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Three alternatives (Proper Address, Parcel Address, Parcel Centroid)\n",
    "addresses['gaddress'] = addresses['REFCAT']+addresses['ROTULO']\n",
    "addresses = addresses[['REFCAT','ROTULO','gaddress','geometry']]\n",
    "df['address'] = df['PCAT']+df['PNP']+df['PLE']\n",
    "df['paddress'] = df['PCAT']+df['PPNP']+df['PPLE']\n",
    "dict_address_points = pd.Series(addresses.geometry.values,index=addresses.gaddress).to_dict()\n",
    "df['refpoint'] = df['address'].map(dict_address_points)\n",
    "dfa = df[df['refpoint'].notnull()]\n",
    "dfb = df[df['refpoint'].isnull()]\n",
    "dfb['refpoint'] = dfb['paddress'].map(dict_address_points)\n",
    "dfc = dfb[dfb['refpoint'].isnull()]             \n",
    "dfb = dfb[dfb['refpoint'].notnull()]\n",
    "dfc['refpoint'] = dfc.apply(lambda row: Point(row.COORX, row.COORY), axis=1) \n",
    "reference_points = pd.concat([dfa,dfb,dfc])\n",
    "reference_points['geometry'] = reference_points['refpoint'] \n",
    "display(reference_points.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process network data and find possible network reference points for land use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need another point where my addresses (entrances) snap to the network, in order to create a significant point of activity along my street network edges. I create a set of possible measure points and snap my addresses to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = gpd.read_file(network_file)\n",
    "#network = network.loc[network['INTEREST2']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create measure points by splitting original network into 50 m chunks and retrieving all the resulting line intersections\n",
    "spl = lines_and_interpolated_vertices(network,100,['id_vial','id_tramo','tipo_vial','clase','firme','tipovehic'])\n",
    "split_interpolated_network = spl[0]\n",
    "modified_network = spl[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_points = get_lines_endpoints(split_interpolated_network)\n",
    "measure_points = gpd.GeoDataFrame(measure_points,columns=['geometry'])\n",
    "measure_points['netpoint'] = measure_points.index\n",
    "display(measure_points.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(reference_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Nearest Parcels\n",
    "final_registers = find_nearest(reference_points,measure_points,'netpoint')\n",
    "final_registers = pd.merge(final_registers,measure_points,how='left',on='netpoint')\n",
    "final_registers['netpointg'] = final_registers['geometry_y']\n",
    "final_registers.drop(columns=['geometry_x','geometry_y'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare final network geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to create edges geometries that are aware of all intersections in my original data, as well as the identified network reference points, so I optimize the number of edges used\n",
    "\n",
    "First, I will grab all the intersections of the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network['geometry'] = network['geometry'].astype('str')\n",
    "original_endpoints = [p.wkt for p in get_lines_endpoints(network)]\n",
    "points_with_activity =  [p.wkt for p in list(final_registers.netpointg.unique())]\n",
    "final_network_points = list(set(original_endpoints+points_with_activity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I will create a network that is split on the new interpolated points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_split_network = split_lines_at_points(modified_network,final_network_points,['id_vial','id_tramo','tipo_vial','clase','firme','tipovehic'],'id_tramo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_split_network = calculate_speed_by_slope(final_split_network,'length','slope')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I need to referr my cadastral registers to the final network points, as the set has changed significantly. I will recreate the index column and relate my reference points to these again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_network_points = pd.DataFrame(final_network_points)\n",
    "final_network_points['netpoint'] = final_network_points.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_registers.drop(columns=['netpoint','netpointg'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(final_registers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_registers['geometry'] = final_registers['refpoint']\n",
    "final_network_points.rename(columns = {0:'geometry'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_network_points['geometry'] = final_network_points.apply(lambda row: Point(loads(row['geometry'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_network_points.to_csv(path+\"\\\\MADRID\\\\final_network_points.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_network_points = gpd.GeoDataFrame(final_network_points,geometry ='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_registers = find_nearest(final_registers,final_network_points,'netpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_registers.rename(columns = {'geometry':'netpointg'},inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_registers.to_csv(path+\"\\\\MADRID\\\\CAT_referenciado.csv\")\n",
    "final_network_points.to_csv(path+\"\\\\MADRID\\\\RED_nodos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_points.to_csv(path+\"\\\\MADRID\\\\measure_points.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_split_network['geometry'] = final_split_network['geometry'].apply(loads)\n",
    "\n",
    "final_split_network = gpd.GeoDataFrame(final_split_network,geometry='geometry')\n",
    "final_split_network.to_file(path+\"\\\\MADRID\\\\edges_loaded.shp\",driver = 'Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_split_network.to_csv(path+\"\\\\MADRID\\\\edges_loaded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
