{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir =r\"C:\\Users\\ManuBenito\\Documents\\GitHub\\project_walknet\"\n",
    "import os, sys, logging\n",
    "os.chdir(dir)\n",
    "sys.path.append(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ManuBenito\\\\Documents\\\\GitHub\\\\project_walknet'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "cfg = ConfigParser()\n",
    "cfg.read(r'./config.ini')\n",
    "DB_CONFIG = {\n",
    "    'database':cfg.get('BBDD_CONNECTION','ddbb'),\n",
    "    'user':cfg.get('BBDD_CONNECTION','user'),\n",
    "    'password':cfg.get('BBDD_CONNECTION','password'),\n",
    "    'host':cfg.get('BBDD_CONNECTION','host'),\n",
    "    'port': cfg.get('BBDD_CONNECTION','port')}\n",
    "DB_CONFIG_URL = f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@localhost:{DB_CONFIG['port']}/{DB_CONFIG['database']}')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Source():\n",
    "        \n",
    "    def __init__(self, keyname=None, provider=None, table=None):\n",
    "        self.keyname = keyname\n",
    "        self.provider = provider\n",
    "        self.table = table\n",
    "        self.data = f\"{cfg.get('DATALAKE','path')}\\\\sources\\\\{keyname}\"\n",
    "    \n",
    "    def run(self, level, **kwargs):\n",
    "        import importlib\n",
    "        s = importlib.import_module(f\"sources.{self.keyname}\",['gather','level0','level1','persist'])            \n",
    "        assert level in ['gather', 'level0','level1','persist'], \"specify a correct level to process\"\n",
    "        if level == 'gather': s.gather(**kwargs)\n",
    "        elif level == 'level0': s.level0(**kwargs)\n",
    "        elif level == 'level1': s.level1(**kwargs)\n",
    "        #elif level == 'persist':\n",
    "            #check\n",
    "            #upload() \n",
    "        \n",
    "    #def inspect()\n",
    "    #def upload()\n",
    "    #def update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "catastro = Source(keyname='catastro', provider='DirecciÃ³n General de Catastro',table='pois')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = [\"28005\",\"28130\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sources.catastro' has no attribute 'level1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m catastro\u001b[39m.\u001b[39mrun(\u001b[39m'\u001b[39m\u001b[39mlevel1\u001b[39m\u001b[39m'\u001b[39m,path \u001b[39m=\u001b[39m catastro\u001b[39m.\u001b[39mdata, codes\u001b[39m=\u001b[39mcodes)\n",
      "Cell \u001b[1;32mIn [4], line 15\u001b[0m, in \u001b[0;36mSource.run\u001b[1;34m(self, level, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mif\u001b[39;00m level \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgather\u001b[39m\u001b[39m'\u001b[39m: s\u001b[39m.\u001b[39mgather(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     14\u001b[0m \u001b[39melif\u001b[39;00m level \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlevel0\u001b[39m\u001b[39m'\u001b[39m: s\u001b[39m.\u001b[39mlevel0(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 15\u001b[0m \u001b[39melif\u001b[39;00m level \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlevel1\u001b[39m\u001b[39m'\u001b[39m: s\u001b[39m.\u001b[39;49mlevel1(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'sources.catastro' has no attribute 'level1'"
     ]
    }
   ],
   "source": [
    "#catastro.run('level1',path = catastro.data, codes=codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = ['gml_id',\n",
    "     'Parcel Cadastral ID',\n",
    "     'Parcel Province Code','Parcel Province Name','Parcel Municipality Code Cadastre', 'Parcel Municipality Code INE','Parcel Municipality Name INE', 'Parcel Street Code', 'Parcel Street Class', 'Parcel Street Name','Parcel First Number', 'Parcel First Letter', 'Parcel Second Number','Parcel Second Letter',\n",
    "     'Parcel Area', 'Parcel Built Area', 'Parcel Built Area Above Ground','Parcel Built Area Under Ground', 'Parcel Built Area Under Cover',\n",
    "     'Building Code ID',\n",
    "     'Building Year Built', 'Building Accuracy Year Built',\n",
    "     'Property gml Number', 'Property gml_id',\n",
    "     'Property ID','Property Cadastral ID',\n",
    "     'Property First Control Character', 'Property Second Control Character','Property Number Cadastre', 'Property Number Municipality','Property Number Land Register',\n",
    "     'Property Street Code', 'Property Street Class', 'Property Street Name', 'Property First Number', 'Property First Letter', 'Property Second Number', 'Property Second Letter','Property Kilometric Point',\n",
    "     'Property Block', 'Property Stairway','Property Floor', 'Property Door Number', 'Property Order Number',\n",
    "     'Property Age', 'Property General Use','Property Land Use Level1',\n",
    "     'Property Built Area','Property Other Area (unbuilt or undivided)','Property Coefficient of property if common elements',\n",
    "     'Property Single or Multiple',\n",
    "     'Part Order Number',\n",
    "     'Part Block', 'Part Stairway', 'Part Floor', 'Part Door',\n",
    "     'Part Detailed Use', 'Part Land Use Level1', 'Part Land Use Level2',\n",
    "     'Part Renovation Kind', 'Part Renovation Year', 'Part Weighted Year',\n",
    "     'Part Is Interior', 'Part Is Common',\n",
    "     'Part Area in Cadastral Terms',\n",
    "     'Part Area in Terrace or Porch', 'Part Area in Other Floors',\n",
    "     'Part Typology', 'Part Typology Level1','Part Typology Level2', 'Part Typology Level3','geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"{path}\\level1\".format(path = catastro.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_logic(df,combination_tuple,end_type,category):\n",
    "       classes = ['Property Land Use Level1', 'Part Typology Level1', 'Part Typology Level2', 'Part Typology Level3', 'Part Land Use Level1', 'Part Land Use Level2']\n",
    "       combination_tuple = tuple(['no'] if not isinstance(x,list) else x for x in combination_tuple)\n",
    "       conditions = \"&\".join([f\"(df['{field}'].isin(combination_tuple[{i}]))\" for i,field in enumerate(classes) if not combination_tuple[i] == ['no']])\n",
    "       df['End Type'] = end_type\n",
    "       print(conditions)\n",
    "       df.loc[eval(conditions),'Walknet Category'] = end_type+\" - \"+category\n",
    "       return df   \n",
    "      \n",
    "def group_data(gdf):\n",
    "    \n",
    "    gdf['x'] = gdf['geometry'].x\n",
    "    gdf['y'] = gdf['geometry'].y\n",
    "\n",
    "    common = ['Parcel Cadastral ID', 'Property Cadastral ID','x','y','End Type','Walknet Category']\n",
    "    local = ['Part Area in Cadastral Terms']\n",
    "\n",
    "    t = gdf.groupby(common).sum()[local]\n",
    "    pv = pd.pivot_table(t.reset_index(),values='Part Area in Cadastral Terms', index = ['Parcel Cadastral ID', 'Property Cadastral ID','x','y'],columns = ['Walknet Category'])\n",
    "    pv = pv.groupby(['x','y']).sum().rename(columns={c:f\"{c} - Area\" for c in pv.columns})\n",
    "    cv = t.groupby(common).count()[local]\n",
    "    cv = pd.pivot_table(cv.reset_index(),values='Part Area in Cadastral Terms', index = ['Parcel Cadastral ID', 'Property Cadastral ID','x','y'],columns = ['Walknet Category'])\n",
    "    cv = cv.groupby(['x','y']).sum().rename(columns={c:f\"{c} - Number\" for c in cv.columns})\n",
    "    df = pd.concat([cv,pv],axis=1).reset_index()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def transform_data(relations, classes, gdf):\n",
    "    \n",
    "    for i,row in relations.iterrows():\n",
    "        combination = tuple(row[col] for col in classes)\n",
    "        end_type = row['End Type']\n",
    "        category = row['Walknet Category']\n",
    "        gdf = apply_logic(gdf,combination,end_type,category) \n",
    "        gdf = group_data(gdf)\n",
    "    return gdf\n",
    "\n",
    "def transform_cadastral_data(path,codes):\n",
    "    \n",
    "    relations = pd.read_excel(r\"C:\\Users\\ManuBenito\\Documents\\GitHub\\walknet\\sources\\spain\\landuse\\catastro\\metadata\\relations.xls\")\n",
    "    classes = ['Property Land Use Level1', 'Part Typology Level1', 'Part Typology Level2', 'Part Typology Level3', 'Part Land Use Level1', 'Part Land Use Level2']\n",
    "    for column in classes:\n",
    "        relations.loc[~relations[column].isna(),column] = relations[column].str.split(\";\")\n",
    "    \n",
    "    if codes: gpkgs = [gpd.read_file(join(path, f)) for f in listdir(path) if isfile(join(path, f)) and f.endswith('.gpkg')]\n",
    "    else: gpkgs = [gpd.read_file(join(path, f)) for f in listdir(path) if isfile(join(path, f)) and f.split(\"-\")[0] in codes and f.endswith('.gpkg')]\n",
    "    print(gpkgs[0].columns)\n",
    "    return [transform_data(relations, classes, gdf) for gdf in gpkgs]\n",
    "    #final = pd.concat([transform_data(relations, gdf) for gdf in gpkgs])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gml_id', 'Parcel Special Asset', 'Parcel Cadastral ID',\n",
      "       'Parcel Province Code', 'Parcel Province Name',\n",
      "       'Parcel Municipality Code Cadastre', 'Parcel Municipality Code INE',\n",
      "       'Parcel Municipality Name INE', 'Parcel Settlement',\n",
      "       'Parcel Street Code', 'Parcel Street Class', 'Parcel Street Name',\n",
      "       'Parcel First Number', 'Parcel First Letter', 'Parcel Second Number',\n",
      "       'Parcel Second Letter', 'Parcel Kilometric Point', 'Parcel Block',\n",
      "       'Parcel Postal Code', 'Parcel Municipality District',\n",
      "       'Parcel Original Municipality Code', 'Parcel Zone Code',\n",
      "       'Parcel Polygon Code', 'Parcel Code', 'Parcel Other Entity Code',\n",
      "       'Parcel Area', 'Parcel Built Area', 'Parcel Built Area Above Ground',\n",
      "       'Parcel Built Area Under Ground', 'Parcel Built Area Under Cover',\n",
      "       'Parcel X Coordinate of Centroid', 'Parcel Y Coordinate of Centroid',\n",
      "       'Parcel Special Asset Code', 'Parcel Special Asset Name', 'Parcel CRS',\n",
      "       'Building Class (Urban, Rural, Special)', 'Building Code ID',\n",
      "       'Building Year Built', 'Building Accuracy Year Built',\n",
      "       'Building Built Area', 'Building Facade Lenght',\n",
      "       'Building Matrix Building',\n",
      "       'Property Building Class (Urban, Rural, Special)', 'Property ID',\n",
      "       'Property First Control Character', 'Property Second Control Character',\n",
      "       'Property Number Cadastre', 'Property Number Municipality',\n",
      "       'Property Number Land Register', 'Property Street Code',\n",
      "       'Property Street Class', 'Property Street Name',\n",
      "       'Property First Number', 'Property First Letter',\n",
      "       'Property Second Number', 'Property Second Letter',\n",
      "       'Property Kilometric Point', 'Property Block', 'Property Stairway',\n",
      "       'Property Floor', 'Property Door Number', 'Property Order Number',\n",
      "       'Property Age', 'Property General Use', 'Property Built Area',\n",
      "       'Property Other Area (unbuilt or undivided)',\n",
      "       'Property Coefficient of property if common elements',\n",
      "       'Part Order Number', 'Part Block', 'Part Stairway', 'Part Floor',\n",
      "       'Part Door', 'Part Detailed Use', 'Part Renovation Kind',\n",
      "       'Part Renovation Year', 'Part Weighted Year', 'Part Is Interior',\n",
      "       'Part Area in Cadastral Terms', 'Part Area in Terrace or Porch',\n",
      "       'Part Area in Other Floors', 'Part Typology', 'Part Is Common',\n",
      "       'Property gml Number', 'Property gml_id', 'Property Single or Multiple',\n",
      "       'Property Cadastral ID', 'Property Land Use Level1',\n",
      "       'Part Land Use Level1', 'Part Land Use Level2', 'Part Typology Level1',\n",
      "       'Part Typology Level2', 'Part Typology Level3', 'geometry'],\n",
      "      dtype='object')\n",
      "(df['Property Land Use Level1'].isin(combination_tuple[0]))&(df['Part Typology Level1'].isin(combination_tuple[1]))&(df['Part Typology Level2'].isin(combination_tuple[2]))&(df['Part Typology Level3'].isin(combination_tuple[3]))&(df['Part Land Use Level1'].isin(combination_tuple[4]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ManuBenito\\AppData\\Local\\Temp\\ipykernel_12092\\4036492222.py:18: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  t = gdf.groupby(common).sum()[local]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(df['Property Land Use Level1'].isin(combination_tuple[0]))&(df['Part Typology Level1'].isin(combination_tuple[1]))&(df['Part Typology Level2'].isin(combination_tuple[2]))&(df['Part Typology Level3'].isin(combination_tuple[3]))&(df['Part Land Use Level1'].isin(combination_tuple[4]))\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Property Land Use Level1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Documents\\Github\\project_walknet\\env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3799\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Documents\\Github\\project_walknet\\env\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Documents\\Github\\project_walknet\\env\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Property Land Use Level1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ls \u001b[39m=\u001b[39m transform_cadastral_data(path,codes)\n",
      "Cell \u001b[1;32mIn [25], line 48\u001b[0m, in \u001b[0;36mtransform_cadastral_data\u001b[1;34m(path, codes)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39melse\u001b[39;00m: gpkgs \u001b[39m=\u001b[39m [gpd\u001b[39m.\u001b[39mread_file(join(path, f)) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m listdir(path) \u001b[39mif\u001b[39;00m isfile(join(path, f)) \u001b[39mand\u001b[39;00m f\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39min\u001b[39;00m codes \u001b[39mand\u001b[39;00m f\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.gpkg\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m     47\u001b[0m \u001b[39mprint\u001b[39m(gpkgs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcolumns)\n\u001b[1;32m---> 48\u001b[0m \u001b[39mreturn\u001b[39;00m [transform_data(relations, classes, gdf) \u001b[39mfor\u001b[39;00m gdf \u001b[39min\u001b[39;00m gpkgs]\n",
      "Cell \u001b[1;32mIn [25], line 48\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39melse\u001b[39;00m: gpkgs \u001b[39m=\u001b[39m [gpd\u001b[39m.\u001b[39mread_file(join(path, f)) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m listdir(path) \u001b[39mif\u001b[39;00m isfile(join(path, f)) \u001b[39mand\u001b[39;00m f\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39min\u001b[39;00m codes \u001b[39mand\u001b[39;00m f\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.gpkg\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m     47\u001b[0m \u001b[39mprint\u001b[39m(gpkgs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcolumns)\n\u001b[1;32m---> 48\u001b[0m \u001b[39mreturn\u001b[39;00m [transform_data(relations, classes, gdf) \u001b[39mfor\u001b[39;00m gdf \u001b[39min\u001b[39;00m gpkgs]\n",
      "Cell \u001b[1;32mIn [25], line 34\u001b[0m, in \u001b[0;36mtransform_data\u001b[1;34m(relations, classes, gdf)\u001b[0m\n\u001b[0;32m     32\u001b[0m     end_type \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mEnd Type\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     33\u001b[0m     category \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mWalknet Category\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 34\u001b[0m     gdf \u001b[39m=\u001b[39m apply_logic(gdf,combination,end_type,category) \n\u001b[0;32m     35\u001b[0m     gdf \u001b[39m=\u001b[39m group_data(gdf)\n\u001b[0;32m     36\u001b[0m \u001b[39mreturn\u001b[39;00m gdf\n",
      "Cell \u001b[1;32mIn [25], line 7\u001b[0m, in \u001b[0;36mapply_logic\u001b[1;34m(df, combination_tuple, end_type, category)\u001b[0m\n\u001b[0;32m      5\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mEnd Type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m end_type\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(conditions)\n\u001b[1;32m----> 7\u001b[0m df\u001b[39m.\u001b[39mloc[\u001b[39meval\u001b[39;49m(conditions),\u001b[39m'\u001b[39m\u001b[39mWalknet Category\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m end_type\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m - \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mcategory\n\u001b[0;32m      8\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32m<string>:1\u001b[0m\n",
      "File \u001b[1;32mc:\\Documents\\Github\\project_walknet\\env\\lib\\site-packages\\pandas\\core\\frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Documents\\Github\\project_walknet\\env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3804\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Property Land Use Level1'"
     ]
    }
   ],
   "source": [
    "ls = transform_cadastral_data(path,codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gml_id', 'Parcel Special Asset', 'Parcel Cadastral ID',\n",
       "       'Parcel Province Code', 'Parcel Province Name',\n",
       "       'Parcel Municipality Code Cadastre', 'Parcel Municipality Code INE',\n",
       "       'Parcel Municipality Name INE', 'Parcel Settlement',\n",
       "       'Parcel Street Code', 'Parcel Street Class', 'Parcel Street Name',\n",
       "       'Parcel First Number', 'Parcel First Letter', 'Parcel Second Number',\n",
       "       'Parcel Second Letter', 'Parcel Kilometric Point', 'Parcel Block',\n",
       "       'Parcel Postal Code', 'Parcel Municipality District',\n",
       "       'Parcel Original Municipality Code', 'Parcel Zone Code',\n",
       "       'Parcel Polygon Code', 'Parcel Code', 'Parcel Other Entity Code',\n",
       "       'Parcel Area', 'Parcel Built Area', 'Parcel Built Area Above Ground',\n",
       "       'Parcel Built Area Under Ground', 'Parcel Built Area Under Cover',\n",
       "       'Parcel X Coordinate of Centroid', 'Parcel Y Coordinate of Centroid',\n",
       "       'Parcel Special Asset Code', 'Parcel Special Asset Name', 'Parcel CRS',\n",
       "       'Building Class (Urban, Rural, Special)', 'Building Code ID',\n",
       "       'Building Year Built', 'Building Accuracy Year Built',\n",
       "       'Building Built Area', 'Building Facade Lenght',\n",
       "       'Building Matrix Building',\n",
       "       'Property Building Class (Urban, Rural, Special)', 'Property ID',\n",
       "       'Property First Control Character', 'Property Second Control Character',\n",
       "       'Property Number Cadastre', 'Property Number Municipality',\n",
       "       'Property Number Land Register', 'Property Street Code',\n",
       "       'Property Street Class', 'Property Street Name',\n",
       "       'Property First Number', 'Property First Letter',\n",
       "       'Property Second Number', 'Property Second Letter',\n",
       "       'Property Kilometric Point', 'Property Block', 'Property Stairway',\n",
       "       'Property Floor', 'Property Door Number', 'Property Order Number',\n",
       "       'Property Age', 'Property General Use', 'Property Built Area',\n",
       "       'Property Other Area (unbuilt or undivided)',\n",
       "       'Property Coefficient of property if common elements',\n",
       "       'Part Order Number', 'Part Block', 'Part Stairway', 'Part Floor',\n",
       "       'Part Door', 'Part Detailed Use', 'Part Renovation Kind',\n",
       "       'Part Renovation Year', 'Part Weighted Year', 'Part Is Interior',\n",
       "       'Part Area in Cadastral Terms', 'Part Area in Terrace or Porch',\n",
       "       'Part Area in Other Floors', 'Part Typology', 'Part Is Common',\n",
       "       'Property gml Number', 'Property gml_id', 'Property Single or Multiple',\n",
       "       'Property Cadastral ID', 'Property Land Use Level1',\n",
       "       'Part Land Use Level1', 'Part Land Use Level2', 'Part Typology Level1',\n",
       "       'Part Typology Level2', 'Part Typology Level3', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\ManuBenito\\Documents\\Walknet-DataLake\\sources\\catastro\\level1\\28005-ALCALA DE HENARES.gpkg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(file)[final_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "relations = pd.read_excel(r\"C:\\Users\\ManuBenito\\Documents\\GitHub\\walknet\\sources\\spain\\landuse\\catastro\\metadata\\relations.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Property Land Use Level1', 'Part Typology Level1', 'Part Typology Level2', 'Part Typology Level3', 'Part Land Use Level1', 'Part Land Use Level2']\n",
    "for column in classes:\n",
    "    relations.loc[~relations[column].isna(),column] = relations[column].str.split(\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_logic(df,combination_tuple,end_type,category):\n",
    "       classes = ['Property Land Use Level1', 'Part Typology Level1', 'Part Typology Level2', 'Part Typology Level3', 'Part Land Use Level1', 'Part Land Use Level2']\n",
    "       combination_tuple = tuple(['no'] if not isinstance(x,list) else x for x in combination_tuple)\n",
    "       conditions = \"&\".join([f\"(df['{field}'].isin(combination_tuple[{i}]))\" for i,field in enumerate(classes) if not combination_tuple[i] == ['no']])\n",
    "       df['End Type'] = end_type\n",
    "       df.loc[eval(conditions),'Walknet Category'] = end_type+\" - \"+category\n",
    "       return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = gdf\n",
    "#df.loc[(df['Property Land Use Level1'].isin(['Housing', 'Sport', 'Storage and Parking']))&(df['Part Typology Level1'].isin(['Housing']))&(df['Part Typology Level2'].isin(['Urban Single Family Residence']))&(df['Part Typology Level3'].isin(['Isolated or Twin', 'Detached or Perimeter Block']))&(df['Part Land Use Level1'].isin(['Housing']))][classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in relations.iterrows():\n",
    "    combination = tuple(row[col] for col in classes)\n",
    "    end_type = row['End Type']\n",
    "    category = row['Walknet Category']\n",
    "    gdf = apply_logic(gdf,combination,end_type,category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['x'] = gdf['geometry'].x\n",
    "gdf['y'] = gdf['geometry'].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = ['Parcel Cadastral ID', 'Property Cadastral ID','x','y','End Type','Walknet Category']\n",
    "local = ['Part Area in Cadastral Terms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = gdf.groupby(common).sum()[local]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv = pd.pivot_table(t.reset_index(),values='Part Area in Cadastral Terms', index = ['Parcel Cadastral ID', 'Property Cadastral ID','x','y'],columns = ['Walknet Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv = pv.groupby(['x','y']).sum().rename(columns={c:f\"{c} - Area\" for c in pv.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = t.groupby(common).count()[local]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = pd.pivot_table(cv.reset_index(),values='Part Area in Cadastral Terms', index = ['Parcel Cadastral ID', 'Property Cadastral ID','x','y'],columns = ['Walknet Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cv.groupby(['x','y']).sum().rename(columns={c:f\"{c} - Number\" for c in cv.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([cv,pv],axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.GeoDataFrame(\n",
    "    df, geometry=gpd.points_from_xy(df.x, df.y)).to_file(r\"C:\\Users\\ManuBenito\\Documents\\Walknet-DataLake\\sources\\catastro\\level2\\28005-ALCALA DE HENARES.gpkg\",driver ='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGUIR CONSOLIDANDO ESTO EN level1\n",
    "COMPROBAR EN MAPA\n",
    " - Pasa algo con Sports. Revisar. Sport Leisure es poca cosa y el resto estÃ¡ en Sport Multiple\n",
    "REFACTORIZAR INCLUSO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "824dd75ae52533d501c48caddb3c0ff1ec19c5804a5e404fe3c18da134102c64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
